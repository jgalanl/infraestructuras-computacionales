{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor: Jesús Galán Llano\n",
    "## Correo: jgalan279@alumno.uned.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el entorno de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p practica1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/media/notebooks/practicas/practica1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/notebooks/practicas/practica1\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1. MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la realización de este ejercicio se ha partido desde el archivo outputlocal que contiene la lista de países y clientes ya unificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"PR\"\t\"Puerto Rico,regular\"\r\n",
      "\"PT\"\t\"Portugal,bueno\"\r\n",
      "\"QA\"\t\"Qatar,bueno\"\r\n",
      "\"US\"\t\"United States,malo\"\r\n",
      "\"US\"\t\"United States,regular\"\r\n",
      "\"US\"\t\"United States,malo\"\r\n",
      "\"US\"\t\"United States,bueno\"\r\n",
      "\"ML\"\t\"Mali,malo\"\r\n",
      "\"GB\"\t\"United Kingdom,regular\"\r\n",
      "\"GB\"\t\"United Kingdom,malo\"\r\n",
      "\"GB\"\t\"United Kingdom,malo\"\r\n",
      "\"GB\"\t\"United Kingdom,malo\"\r\n",
      "\"GG\"\t\"Guernsey,malo\"\r\n",
      "\"RE\"\t\"R\\u00e9union,regular\"\r\n",
      "\"RO\"\t\"Romania,malo\"\r\n",
      "\"SB\"\t\"Solomon Islands,regular\"\r\n",
      "\"SI\"\t\"Slovenia,regular\"\r\n",
      "\"MT\"\t\"Malta,regular\"\r\n",
      "\"MV\"\t\"Maldives,malo\"\r\n",
      "\"IT\"\t\"Italy,malo\"\r\n",
      "\"IT\"\t\"Italy,regular\"\r\n",
      "\"AE\"\t\"United Arab Emirates,regular\"\r\n",
      "\"LK\"\t\"Sri Lanka,malo\"\r\n",
      "\"LK\"\t\"Sri Lanka,malo\"\r\n",
      "\"TM\"\t\"Turkmenistan,regular\"\r\n",
      "\"TR\"\t\"Turkey,bueno\"\r\n",
      "\"TT\"\t\"Trinidad and Tobago,regular\"\r\n",
      "\"ES\"\t\"Spain,regular\"\r\n",
      "\"ES\"\t\"Spain,bueno\"\r\n",
      "\"ES\"\t\"Spain,regular\"\r\n",
      "\"ES\"\t\"Spain,malo\"\r\n",
      "\"ES\"\t\"Spain,bueno\"\r\n",
      "\"ES\"\t\"Spain,malo\"\r\n",
      "\"ES\"\t\"Spain,bueno\"\r\n",
      "\"GN\"\t\"Guinea,bueno\"\r\n",
      "\"GS\"\t\"South Georgia and the South Sandwich Islands,malo\"\r\n",
      "\"GS\"\t\"South Georgia and the South Sandwich Islands,bueno\"\r\n",
      "\"GT\"\t\"Guatemala,regular\"\r\n",
      "\"GU\"\t\"Guam,bueno\"\r\n",
      "\"GU\"\t\"Guam,bueno\"\r\n",
      "\"GU\"\t\"Guam,bueno\"\r\n",
      "\"GW\"\t\"Guinea-Bissau,regular\"\r\n",
      "\"ZA\"\t\"South Africa,bueno\"\r\n",
      "\"ZA\"\t\"South Africa,regular\"\r\n",
      "\"CA\"\t\"Canada,regular\"\r\n",
      "\"CA\"\t\"Canada,bueno\"\r\n",
      "\"SO\"\t\"Somalia,malo\"\r\n",
      "\"SO\"\t\"Somalia,bueno\"\r\n",
      "\"SS\"\t\"South Sudan,malo\"\r\n",
      "\"SS\"\t\"South Sudan,bueno\"\r\n"
     ]
    }
   ],
   "source": [
    "cat outputlocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este archivo se ha obtenido tras ejecutar el programa mrjob-join, que venía a modo de ejemplo al comienzo de la práctica. Este código se ha modificado únicamente el formato de salida de la función reduce para simplificar la lectura de los datos en los siguientes apartados. El código se incluye a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob-ejercicio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob-ejercicio.py\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Realiza la ordenacion secundaria\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, _, line):\n",
    "    splits = line.rstrip(\"\\n\").split(\",\")\n",
    "\n",
    "    if len(splits) == 2: # datos de paises\n",
    "      symbol = 'A' # ordenamos los paises antes que los datos de personas\n",
    "      country2digit = splits[1]\n",
    "      yield country2digit, [symbol, splits]\n",
    "    else: #  datos de personas\n",
    "      symbol = 'B'\n",
    "      country2digit = splits[2]\n",
    "      yield country2digit, [symbol, splits]\n",
    "    \n",
    "    line = line.rstrip(\"\\n\").split('\t')\n",
    "    country, value = line[1].split(',')\n",
    "    country, value = country.replace('\"', ''), value.replace('\"', '')\n",
    "    if value == 'bueno':\n",
    "        yield country, 1\n",
    "\n",
    "  def reducer(self, key, values):\n",
    "    countries = [] # paises primero ya que llevan la clave 'A'\n",
    "    for value in values:\n",
    "      if value[0] == 'A':\n",
    "        countries.append(value)\n",
    "      if value[0] == 'B':\n",
    "        for country in countries:\n",
    "            # Modificar el formato de salida original para facilitar el procesamiento\n",
    "            yield key, f'{country[1][0]},{value[1][1]}'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.1: Contador de clientes valorados por países."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este programa cuenta el número de clientes \"buenos\" por cada país. El número de pasos del programa es de dos: en primer lugar se realiza una función map y seguidamente se ejecuta una función reduce. La función map se encarga de leer los datos del archivo de entrada y de identificar a los clientes categorizados como buenos. Para ello, divide los datos de entrada, separados por el caracter \",\", y guarda el país y la categoría. Si la categoría tiene el valor \"bueno\" devuelve un par <clave,valor> donde la clave es el nombre del país y el valor es 1. En el último paso, la función reduce encarga de calcular el sumatorio de la entrada para todos los países. Para este cálculo se utiliza la función sum() de Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio11.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio11.py\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Realiza la ordenacion secundaria\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, key, line):\n",
    "    line = line.rstrip(\"\\n\").split('\t')\n",
    "    country, value = line[1].split(',')\n",
    "    country, value = country.replace('\"', ''), value.replace('\"', '')\n",
    "    if value == 'bueno':\n",
    "        yield country, 1\n",
    "    \n",
    "  def reducer(self, key, values):\n",
    "    yield (key, sum(values)) \n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero ejecutamos el códigoen local y luego en Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/ejercicio11.root.20211117.234225.913325\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/ejercicio11.root.20211117.234225.913325/output\n",
      "Streaming final output from /tmp/ejercicio11.root.20211117.234225.913325/output...\n",
      "Removing temp directory /tmp/ejercicio11.root.20211117.234225.913325...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio11.py outputlocal > outputlocal11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"South Georgia and the South Sandwich Islands\"\t1\r\n",
      "\"Spain\"\t3\r\n",
      "\"Qatar\"\t1\r\n",
      "\"Somalia\"\t1\r\n",
      "\"Canada\"\t1\r\n",
      "\"Guam\"\t3\r\n",
      "\"Turkey\"\t1\r\n",
      "\"United States\"\t1\r\n",
      "\"South Africa\"\t1\r\n",
      "\"South Sudan\"\t1\r\n",
      "\"Guinea\"\t1\r\n",
      "\"Portugal\"\t1\r\n"
     ]
    }
   ],
   "source": [
    "! cat outputlocal11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /tmp/ej11\n",
    "! hdfs dfs -put /media/notebooks/practicas/practica1/outputlocal /tmp/ej11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 root supergroup       1236 2021-11-18 00:42 /tmp/ej11/outputlocal\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls  /tmp/ej11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/tmp/ej11-output/*': No such file or directory\n",
      "rmdir: `/tmp/ej11-output': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /tmp/ej11-output/*\n",
    "! hdfs dfs -rmdir /tmp/ej11-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /app/hadoop-3.3.1/bin...\n",
      "Found hadoop binary: /app/hadoop-3.3.1/bin/hadoop\n",
      "Using Hadoop version 3.3.1\n",
      "Looking for Hadoop streaming jar in /app/hadoop-3.3.1...\n",
      "Found Hadoop streaming jar: /app/hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar\n",
      "Creating temp directory /tmp/ejercicio11.root.20211117.234243.810072\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/ejercicio11.root.20211117.234243.810072/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/ejercicio11.root.20211117.234243.810072/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar4457515230502276056/] [] /tmp/streamjob3386770937057026826.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.7:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.7:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1637192506404_0001\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1637192506404_0001\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1637192506404_0001\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0001/\n",
      "  Running job: job_1637192506404_0001\n",
      "  Job job_1637192506404_0001 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1637192506404_0001 completed successfully\n",
      "  Output directory: hdfs:///tmp/ej11-output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1854\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=187\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=279\n",
      "\t\tFILE: Number of bytes written=836267\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2040\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=187\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=6855680\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2063360\n",
      "\t\tTotal time spent by all map tasks (ms)=6695\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6695\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2015\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2015\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6695\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2015\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1600\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=160\n",
      "\t\tInput split bytes=186\n",
      "\t\tMap input records=50\n",
      "\t\tMap output bytes=241\n",
      "\t\tMap output materialized bytes=285\n",
      "\t\tMap output records=16\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=290955264\n",
      "\t\tPeak Map Virtual memory (bytes)=2558234624\n",
      "\t\tPeak Reduce Physical memory (bytes)=188678144\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2565910528\n",
      "\t\tPhysical memory (bytes) snapshot=767184896\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=12\n",
      "\t\tReduce shuffle bytes=285\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=32\n",
      "\t\tTotal committed heap usage (bytes)=698875904\n",
      "\t\tVirtual memory (bytes) snapshot=7680897024\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///tmp/ej11-output\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/ejercicio11.root.20211117.234243.810072...\n",
      "Removing temp directory /tmp/ejercicio11.root.20211117.234243.810072...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio11.py hdfs:///tmp/ej11/* -r hadoop --output-dir hdfs:///tmp/ej11-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Canada\"\t1\r\n",
      "\"Guam\"\t3\r\n",
      "\"Guinea\"\t1\r\n",
      "\"Portugal\"\t1\r\n",
      "\"Qatar\"\t1\r\n",
      "\"Somalia\"\t1\r\n",
      "\"South Africa\"\t1\r\n",
      "\"South Georgia and the South Sandwich Islands\"\t1\r\n",
      "\"South Sudan\"\t1\r\n",
      "\"Spain\"\t3\r\n",
      "\"Turkey\"\t1\r\n",
      "\"United States\"\t1\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -tail /tmp/ej11-output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.2. País con mejores clientes. Mostrar el país con mayor número de clientes valorados como \"bueno\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este programa permite obtener el país con mejores clientes considerados \"buenos\". El programa necesita de cuatro pasos totales, si se cuentan los dos primeros pasos que se corresponden con las funciones map y reduce del programa del apartado 1.1. La nueva función mapper, mapper2, recibe de entrada la salida del programa del apartado 1.1, es decir, un conjunto de <claves,valor> donde la clave es el nombre del país y el valor es el número de clientes categorizados como buenos. Una vez recibe los datos, la función realiza una conversión de los valores a entero, por si hubiera algún dato que no fuera correcto, y retorna todos los pares <clave,valor>, pero sin devolver la clave. De esta forma se envía un generador a la siguiente función reduce para que pueda utilizar todos los datos. Por último, la función reduce se encarga de realizar una operación de maximización sobre los datos recibidos para calcular el país con mayor número de clientes considerados buenos. Utiliza la función max() de Python para realizar este cálculo. Para establecer un orden de ejecución de las funciones map y reduce utilizamos el método steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio12.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio12.py\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Realiza la ordenacion secundaria\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, key, line):\n",
    "    line = line.rstrip(\"\\n\").split('\t')\n",
    "    country, value = line[1].split(',')\n",
    "    country, value = country.replace('\"', ''), value.replace('\"', '')\n",
    "    if value == 'bueno':\n",
    "        yield country, 1\n",
    "    \n",
    "  def reducer(self, key, values):\n",
    "    yield (key, sum(values))\n",
    "    \n",
    "  def mapper2(self, key, values):\n",
    "    values = int(values)\n",
    "    yield None, (values,key)\n",
    "    \n",
    "  def reducer2(self, _, values):\n",
    "    yield (max(values))\n",
    "    \n",
    "  def steps(self):\n",
    "    return [\n",
    "        MRStep(mapper=self.mapper, reducer=self.reducer),\n",
    "        MRStep(mapper=self.mapper2, reducer=self.reducer2)\n",
    "    ]\n",
    "         \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero ejecutamos el códigoen local y luego en Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/ejercicio12.root.20211117.231108.125077\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/ejercicio12.root.20211117.231108.125077/output\n",
      "Streaming final output from /tmp/ejercicio12.root.20211117.231108.125077/output...\n",
      "Removing temp directory /tmp/ejercicio12.root.20211117.231108.125077...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio12.py outputlocal > outputlocal12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t\"Spain\"\r\n"
     ]
    }
   ],
   "source": [
    "! cat outputlocal12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `/tmp/ej12': File exists\n",
      "put: `/tmp/ej12/outputlocal': File exists\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir /tmp/ej12\n",
    "! hdfs dfs -put /media/notebooks/practicas/practica1/outputlocal  /tmp/ej12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 root supergroup       1236 2021-11-18 00:11 /tmp/ej12/outputlocal\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls  /tmp/ej12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/tmp/ej12-output/*': No such file or directory\n",
      "rmdir: `/tmp/ej12-output': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /tmp/ej12-output/*\n",
    "! hdfs dfs -rmdir /tmp/ej12-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /app/hadoop-3.3.1/bin...\n",
      "Found hadoop binary: /app/hadoop-3.3.1/bin/hadoop\n",
      "Using Hadoop version 3.3.1\n",
      "Looking for Hadoop streaming jar in /app/hadoop-3.3.1...\n",
      "Found Hadoop streaming jar: /app/hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar\n",
      "Creating temp directory /tmp/ejercicio12.root.20211117.231153.727142\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/ejercicio12.root.20211117.231153.727142/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/ejercicio12.root.20211117.231153.727142/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar3507074732095050767/] [] /tmp/streamjob8335111148641592053.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1637190633114_0001\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1637190633114_0001\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1637190633114_0001\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1637190633114_0001/\n",
      "  Running job: job_1637190633114_0001\n",
      "  Job job_1637190633114_0001 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1637190633114_0001 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/ejercicio12.root.20211117.231153.727142/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1854\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=187\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=279\n",
      "\t\tFILE: Number of bytes written=836450\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2040\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=187\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9523200\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3268608\n",
      "\t\tTotal time spent by all map tasks (ms)=9300\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9300\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3192\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3192\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9300\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3192\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1620\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=143\n",
      "\t\tInput split bytes=186\n",
      "\t\tMap input records=50\n",
      "\t\tMap output bytes=241\n",
      "\t\tMap output materialized bytes=285\n",
      "\t\tMap output records=16\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=271486976\n",
      "\t\tPeak Map Virtual memory (bytes)=2558992384\n",
      "\t\tPeak Reduce Physical memory (bytes)=185483264\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2561470464\n",
      "\t\tPhysical memory (bytes) snapshot=726835200\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=12\n",
      "\t\tReduce shuffle bytes=285\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=32\n",
      "\t\tTotal committed heap usage (bytes)=697827328\n",
      "\t\tVirtual memory (bytes) snapshot=7678291968\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar4840900356300551594/] [] /tmp/streamjob9148864951932723528.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1637190633114_0002\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1637190633114_0002\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1637190633114_0002\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1637190633114_0002/\n",
      "  Running job: job_1637190633114_0002\n",
      "  Job job_1637190633114_0002 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1637190633114_0002 completed successfully\n",
      "  Output directory: hdfs:///tmp/ej12-output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=281\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=10\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=325\n",
      "\t\tFILE: Number of bytes written=836557\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=601\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=10\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=4424704\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1871872\n",
      "\t\tTotal time spent by all map tasks (ms)=4321\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4321\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1828\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1828\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4321\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1828\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1440\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=121\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=12\n",
      "\t\tMap output bytes=295\n",
      "\t\tMap output materialized bytes=331\n",
      "\t\tMap output records=12\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=290590720\n",
      "\t\tPeak Map Virtual memory (bytes)=2558763008\n",
      "\t\tPeak Reduce Physical memory (bytes)=186707968\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2561667072\n",
      "\t\tPhysical memory (bytes) snapshot=766517248\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=12\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=331\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=24\n",
      "\t\tTotal committed heap usage (bytes)=695205888\n",
      "\t\tVirtual memory (bytes) snapshot=7678595072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///tmp/ej12-output\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/ejercicio12.root.20211117.231153.727142...\n",
      "Removing temp directory /tmp/ejercicio12.root.20211117.231153.727142...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio12.py hdfs:///tmp/ej12/* -r hadoop --output-dir hdfs:///tmp/ej12-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t\"Spain\"\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -tail /tmp/ej12-output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1.3. País con mejores clientes mejorado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este programa resuelve el problema del apartado 1.2, que es devolver un único país en el caso de que haya más de uno que tenga el mismo número máximo de clientes considerados \"buenos\". El programa consta de las mismas fases que el programa del apartado anterior y todas realizan la misma funcionalidad, a excepción de la segunda función reduce. Esta función se encarga primero de guardar los datos de entrada como una lista y de calcular su valor máximo, que se corresponde con el valor más alto de clientes categorizados como \"buenos\". Tras obtener este máximo, la función recorre la lista de países y, en aquellos donde el máximo coincida con el número de clientes \"buenos\", devuelve una tupla <clave,valor> con el nombre del país. De esta forma se obtiene una serie de países y no únicamente uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio13.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio13.py\n",
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Realiza la ordenacion secundaria\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, key, line):\n",
    "    line = line.rstrip(\"\\n\").split('\t')\n",
    "    country, value = line[1].split(',')\n",
    "    country, value = country.replace('\"', ''), value.replace('\"', '')\n",
    "    if value == 'bueno':\n",
    "        yield country, 1\n",
    "        \n",
    "  def reducer(self, key, values):\n",
    "    yield (key, sum(values))\n",
    "    \n",
    "  def mapper2(self, key, values):\n",
    "    yield None, (values,key)\n",
    "    \n",
    "  def reducer2(self, key, values):\n",
    "    values = list(values)\n",
    "    maxv = (max(values))\n",
    "    for value in values:\n",
    "        if value[0] == maxv[0]:\n",
    "            yield value[0], value[1]    \n",
    "\n",
    "  def steps(self):\n",
    "    return [\n",
    "        MRStep(mapper=self.mapper, reducer=self.reducer),\n",
    "        MRStep(mapper=self.mapper2, reducer=self.reducer2)\n",
    "    ]\n",
    "         \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/ejercicio13.root.20211117.231347.061460\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/ejercicio13.root.20211117.231347.061460/output\n",
      "Streaming final output from /tmp/ejercicio13.root.20211117.231347.061460/output...\n",
      "Removing temp directory /tmp/ejercicio13.root.20211117.231347.061460...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio13.py outputlocal > outputlocal13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero ejecutamos el códigoen local y luego en Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/ejercicio13.root.20211117.231349.302033\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/ejercicio13.root.20211117.231349.302033/output\n",
      "Streaming final output from /tmp/ejercicio13.root.20211117.231349.302033/output...\n",
      "Removing temp directory /tmp/ejercicio13.root.20211117.231349.302033...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio13.py outputlocal > outputlocal13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t\"Guam\"\r\n",
      "3\t\"Spain\"\r\n"
     ]
    }
   ],
   "source": [
    "! cat outputlocal13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir /tmp/ej13\n",
    "! hdfs dfs -put /media/notebooks/practicas/practica1/outputlocal  /tmp/ej13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 root supergroup       1236 2021-11-18 00:14 /tmp/ej13/outputlocal\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls  /tmp/ej13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/tmp/ej13-output/*': No such file or directory\n",
      "rmdir: `/tmp/ej13-output': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /tmp/ej13-output/*\n",
    "! hdfs dfs -rmdir /tmp/ej13-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /app/hadoop-3.3.1/bin...\n",
      "Found hadoop binary: /app/hadoop-3.3.1/bin/hadoop\n",
      "Using Hadoop version 3.3.1\n",
      "Looking for Hadoop streaming jar in /app/hadoop-3.3.1...\n",
      "Found Hadoop streaming jar: /app/hadoop-3.3.1/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar\n",
      "Creating temp directory /tmp/ejercicio13.root.20211117.231443.929168\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/ejercicio13.root.20211117.231443.929168/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/ejercicio13.root.20211117.231443.929168/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar5206616686777112180/] [] /tmp/streamjob4518172108230057195.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1637190633114_0003\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1637190633114_0003\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1637190633114_0003\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1637190633114_0003/\n",
      "  Running job: job_1637190633114_0003\n",
      "  Job job_1637190633114_0003 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1637190633114_0003 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/ejercicio13.root.20211117.231443.929168/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1854\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=187\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=279\n",
      "\t\tFILE: Number of bytes written=836450\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2040\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=187\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=4771840\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2203648\n",
      "\t\tTotal time spent by all map tasks (ms)=4660\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4660\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2152\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2152\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4660\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2152\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1480\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=153\n",
      "\t\tInput split bytes=186\n",
      "\t\tMap input records=50\n",
      "\t\tMap output bytes=241\n",
      "\t\tMap output materialized bytes=285\n",
      "\t\tMap output records=16\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=286326784\n",
      "\t\tPeak Map Virtual memory (bytes)=2557952000\n",
      "\t\tPeak Reduce Physical memory (bytes)=187498496\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2562285568\n",
      "\t\tPhysical memory (bytes) snapshot=759955456\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=12\n",
      "\t\tReduce shuffle bytes=285\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=32\n",
      "\t\tTotal committed heap usage (bytes)=696254464\n",
      "\t\tVirtual memory (bytes) snapshot=7677861888\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar5229653492737326872/] [] /tmp/streamjob2427741070448835918.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.2:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1637190633114_0004\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1637190633114_0004\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1637190633114_0004\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1637190633114_0004/\n",
      "  Running job: job_1637190633114_0004\n",
      "  Job job_1637190633114_0004 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1637190633114_0004 completed successfully\n",
      "  Output directory: hdfs:///tmp/ej13-output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=281\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=19\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=325\n",
      "\t\tFILE: Number of bytes written=836557\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=601\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=19\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=4362240\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1857536\n",
      "\t\tTotal time spent by all map tasks (ms)=4260\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4260\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1814\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1814\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4260\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1814\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1380\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=152\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=12\n",
      "\t\tMap output bytes=295\n",
      "\t\tMap output materialized bytes=331\n",
      "\t\tMap output records=12\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=290320384\n",
      "\t\tPeak Map Virtual memory (bytes)=2560409600\n",
      "\t\tPeak Reduce Physical memory (bytes)=186707968\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2561437696\n",
      "\t\tPhysical memory (bytes) snapshot=766091264\n",
      "\t\tReduce input groups=12\n",
      "\t\tReduce input records=12\n",
      "\t\tReduce output records=2\n",
      "\t\tReduce shuffle bytes=331\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=24\n",
      "\t\tTotal committed heap usage (bytes)=697303040\n",
      "\t\tVirtual memory (bytes) snapshot=7679614976\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///tmp/ej13-output\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/ejercicio13.root.20211117.231443.929168...\n",
      "Removing temp directory /tmp/ejercicio13.root.20211117.231443.929168...\n"
     ]
    }
   ],
   "source": [
    "! python3 ejercicio13.py hdfs:///tmp/ej13/* -r hadoop --output-dir hdfs:///tmp/ej13-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t\"Guam\"\r\n",
      "3\t\"Spain\"\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -tail /tmp/ej13-output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2. Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se comprueba la conexión con la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004629_44ba1bb7-834c-44c9-bcb0-0cc8eb21136a): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004629_44ba1bb7-834c-44c9-bcb0-0cc8eb21136a); Time taken: 0.011 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004629_44ba1bb7-834c-44c9-bcb0-0cc8eb21136a): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004629_44ba1bb7-834c-44c9-bcb0-0cc8eb21136a); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| default        |\n",
      "| practica       |\n",
      "+----------------+\n",
      "2 rows selected (0.106 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"SHOW DATABASES;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004635_0a1c8fce-4671-42a4-9942-923baeae717d): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004635_0a1c8fce-4671-42a4-9942-923baeae717d); Time taken: 0.013 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004635_0a1c8fce-4671-42a4-9942-923baeae717d): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004635_0a1c8fce-4671-42a4-9942-923baeae717d); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| default        |\n",
      "| practica       |\n",
      "+----------------+\n",
      "2 rows selected (0.109 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -n \"bigdata\" -p \"bigdata\" -e \"SHOW DATABASES;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Crear las tablas necesarias para almacenar datos\n",
    "\n",
    "Se ha decidido crear las tablas de forma interna debido a: facilitar la manipulación de los datos a Hive y porque en el contexto de la práctica ninguna otra aplicación va a hacer a los datos que se almacenen. En el caso de que hubiera otras aplicaciones que quisieran acceder a los datos se hubiera adoptado por crear las tablas de forma externa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, creamos la base de datos que almacenará las tablas que serán creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004641_fdf4f16e-e2f2-487c-a776-e928fbdbf1d2): CREATE DATABASE IF NOT EXISTS practica COMMENT 'practica1' WITH DBPROPERTIES ('Creada por' = 'BigData', 'Fecha' = '09/11/21')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004641_fdf4f16e-e2f2-487c-a776-e928fbdbf1d2); Time taken: 0.016 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004641_fdf4f16e-e2f2-487c-a776-e928fbdbf1d2): CREATE DATABASE IF NOT EXISTS practica COMMENT 'practica1' WITH DBPROPERTIES ('Creada por' = 'BigData', 'Fecha' = '09/11/21')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004641_fdf4f16e-e2f2-487c-a776-e928fbdbf1d2); Time taken: 0.014 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.086 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE DATABASE IF NOT EXISTS practica \\\n",
    "COMMENT 'practica1' \\\n",
    "WITH DBPROPERTIES ('Creada por' = 'BigData', 'Fecha' = '09/11/21')\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\"  -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que se ha creado la base de datos correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004647_1207e649-fd8f-454d-9273-7f17c95e9b3d): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004647_1207e649-fd8f-454d-9273-7f17c95e9b3d); Time taken: 0.012 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004647_1207e649-fd8f-454d-9273-7f17c95e9b3d): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004647_1207e649-fd8f-454d-9273-7f17c95e9b3d); Time taken: 0.012 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| default        |\n",
      "| practica       |\n",
      "+----------------+\n",
      "2 rows selected (0.109 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"SHOW DATABASES;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las tablas en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004652_a36daab2-b9c9-4267-a90c-ef15da5f1942): DROP TABLE author\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004652_a36daab2-b9c9-4267-a90c-ef15da5f1942); Time taken: 0.016 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004652_a36daab2-b9c9-4267-a90c-ef15da5f1942): DROP TABLE author\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004652_a36daab2-b9c9-4267-a90c-ef15da5f1942); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.073 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE author;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004657_febd442a-a3ba-4105-a0d0-eccebfa6ecef): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004657_febd442a-a3ba-4105-a0d0-eccebfa6ecef); Time taken: 0.015 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004657_febd442a-a3ba-4105-a0d0-eccebfa6ecef): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004657_febd442a-a3ba-4105-a0d0-eccebfa6ecef); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.074 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118004657_afb64a7a-1a03-422f-a4b1-436365582c28): CREATE TABLE IF NOT EXISTS author(author_id INT, author_name STRING) COMMENT 'Autores con id y nombre' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004657_afb64a7a-1a03-422f-a4b1-436365582c28); Time taken: 0.074 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004657_afb64a7a-1a03-422f-a4b1-436365582c28): CREATE TABLE IF NOT EXISTS author(author_id INT, author_name STRING) COMMENT 'Autores con id y nombre' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004657_afb64a7a-1a03-422f-a4b1-436365582c28); Time taken: 0.396 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.478 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS author(author_id INT, author_name STRING) \\\n",
    "COMMENT 'Autores con id y nombre' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004703_70bbf1d3-238c-4c6b-ad9b-e7bbb6b6a459): DROP TABLE dataset\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004703_70bbf1d3-238c-4c6b-ad9b-e7bbb6b6a459); Time taken: 0.014 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004703_70bbf1d3-238c-4c6b-ad9b-e7bbb6b6a459): DROP TABLE dataset\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004703_70bbf1d3-238c-4c6b-ad9b-e7bbb6b6a459); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.067 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE dataset;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004708_c2adec38-b4a5-4ebb-93e0-a4d489a79b09): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004708_c2adec38-b4a5-4ebb-93e0-a4d489a79b09); Time taken: 0.015 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004708_c2adec38-b4a5-4ebb-93e0-a4d489a79b09): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004708_c2adec38-b4a5-4ebb-93e0-a4d489a79b09); Time taken: 0.02 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.083 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118004708_3b256582-fa2c-48b8-ba90-5ada4f62453e): CREATE TABLE IF NOT EXISTS dataset(title STRING, author_id INT, bestsellers_rank INT, imprint STRING, publication_date DATE, rating_avg FLOAT, rating_count INT) COMMENT 'Libros con su informacion y autores' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004708_3b256582-fa2c-48b8-ba90-5ada4f62453e); Time taken: 0.024 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004708_3b256582-fa2c-48b8-ba90-5ada4f62453e): CREATE TABLE IF NOT EXISTS dataset(title STRING, author_id INT, bestsellers_rank INT, imprint STRING, publication_date DATE, rating_avg FLOAT, rating_count INT) COMMENT 'Libros con su informacion y autores' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004708_3b256582-fa2c-48b8-ba90-5ada4f62453e); Time taken: 0.059 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.092 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS dataset(title STRING, author_id INT, bestsellers_rank INT, \\\n",
    "imprint STRING, publication_date DATE, rating_avg FLOAT, rating_count INT) \\\n",
    "COMMENT 'Libros con su informacion y autores' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que ambas tablas se han creado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004714_e1406f9c-32f6-4c03-956f-f769effdee2c): SHOW TABLES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004714_e1406f9c-32f6-4c03-956f-f769effdee2c); Time taken: 0.016 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004714_e1406f9c-32f6-4c03-956f-f769effdee2c): SHOW TABLES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004714_e1406f9c-32f6-4c03-956f-f769effdee2c); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-----------+\n",
      "| tab_name  |\n",
      "+-----------+\n",
      "| author    |\n",
      "| dataset   |\n",
      "+-----------+\n",
      "2 rows selected (0.108 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"SHOW TABLES;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Importar los datos en las tablas creadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, copiamos los datasets en HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal authors.csv /user/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal dataset.csv /user/root/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datasets en HDFS, los importamos en su tabla correspondiente comprobando que se han cargado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004727_d2cb26fb-fd93-4c21-ac05-1981cd6d118f): LOAD DATA INPATH 'authors.csv' INTO TABLE author\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004727_d2cb26fb-fd93-4c21-ac05-1981cd6d118f); Time taken: 0.216 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004727_d2cb26fb-fd93-4c21-ac05-1981cd6d118f): LOAD DATA INPATH 'authors.csv' INTO TABLE author\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.author from hdfs://namenode:8020/user/root/authors.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004727_d2cb26fb-fd93-4c21-ac05-1981cd6d118f); Time taken: 0.279 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.549 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"LOAD DATA INPATH 'authors.csv' INTO TABLE author;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los datos están cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004735_bd4610a6-d63a-4963-8d87-ce089869f7c8): SELECT * FROM author LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:author.author_id, type:int, comment:null), FieldSchema(name:author.author_name, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004735_bd4610a6-d63a-4963-8d87-ce089869f7c8); Time taken: 0.973 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004735_bd4610a6-d63a-4963-8d87-ce089869f7c8): SELECT * FROM author LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20211118004735_bd4610a6-d63a-4963-8d87-ce089869f7c8); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-------------------+---------------------+\n",
      "| author.author_id  | author.author_name  |\n",
      "+-------------------+---------------------+\n",
      "| 3                 | Cecelia Mecca       |\n",
      "| 4                 | Ana Maria Spagna    |\n",
      "| 5                 | Mark Vanhoenacker   |\n",
      "| 6                 | Jen Gale            |\n",
      "| 7                 | Giles Chapman       |\n",
      "| 10                | Brian Cosgrove      |\n",
      "| 17                | David Nash          |\n",
      "| 18                | Mike Gould          |\n",
      "| 19                | Cy Tymony           |\n",
      "| 20                | Haynes Publishing   |\n",
      "+-------------------+---------------------+\n",
      "10 rows selected (1.085 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM author LIMIT 10;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No ejecutar\n",
    "sql_statement = \"LOAD DATA INPATH 'dataset.csv' INTO TABLE dataset;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que el formato de la fecha del archivo dataset.csv no se se corresponde con el que soporta HIVE se debe \n",
    "realizar un proceso intermedio para su carga. \n",
    "Este proceso consiste en crear una tabla temporal que almacene la fecha como string para seguidamente\n",
    "cargar todos los datos de esa tabla en otra. El formato de la fecha se modifica antes de la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004742_a485cb7d-eff0-4034-8abc-681145865814): DROP TABLE dataset_inter\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004742_a485cb7d-eff0-4034-8abc-681145865814); Time taken: 0.015 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004742_a485cb7d-eff0-4034-8abc-681145865814): DROP TABLE dataset_inter\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004742_a485cb7d-eff0-4034-8abc-681145865814); Time taken: 0.014 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.093 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE dataset_inter;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004747_bd069a6e-28c3-422d-846d-b730b00d8c19): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004747_bd069a6e-28c3-422d-846d-b730b00d8c19); Time taken: 0.014 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004747_bd069a6e-28c3-422d-846d-b730b00d8c19): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004747_bd069a6e-28c3-422d-846d-b730b00d8c19); Time taken: 0.009 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.08 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118004747_55792618-3e8e-488c-833f-73174c38dfb8): CREATE TABLE IF NOT EXISTS dataset_inter(title STRING, author_id INT, bestsellers_rank INT, imprint STRING, publication_date STRING, rating_avg FLOAT, rating_count INT) COMMENT 'Libros con su informacion y autores' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004747_55792618-3e8e-488c-833f-73174c38dfb8); Time taken: 0.02 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004747_55792618-3e8e-488c-833f-73174c38dfb8): CREATE TABLE IF NOT EXISTS dataset_inter(title STRING, author_id INT, bestsellers_rank INT, imprint STRING, publication_date STRING, rating_avg FLOAT, rating_count INT) COMMENT 'Libros con su informacion y autores' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004747_55792618-3e8e-488c-833f-73174c38dfb8); Time taken: 0.043 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.073 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS dataset_inter(title STRING, author_id INT, bestsellers_rank INT, \\\n",
    "imprint STRING, publication_date STRING, rating_avg FLOAT, rating_count INT) \\\n",
    "COMMENT 'Libros con su informacion y autores' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\;' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en la tabla intermedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/user/root/dataset.csv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -copyFromLocal dataset.csv /user/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004755_8b13aa61-58d6-4e10-933c-b17f6dd32983): LOAD DATA INPATH 'dataset.csv' INTO TABLE dataset_inter\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004755_8b13aa61-58d6-4e10-933c-b17f6dd32983); Time taken: 0.034 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004755_8b13aa61-58d6-4e10-933c-b17f6dd32983): LOAD DATA INPATH 'dataset.csv' INTO TABLE dataset_inter\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.dataset_inter from hdfs://namenode:8020/user/root/dataset.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004755_8b13aa61-58d6-4e10-933c-b17f6dd32983); Time taken: 0.154 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.235 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"LOAD DATA INPATH 'dataset.csv' INTO TABLE dataset_inter;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los datos están cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004802_056d7afd-8355-44fc-b33b-a99b44da1aea): SELECT * FROM dataset_inter LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:dataset_inter.title, type:string, comment:null), FieldSchema(name:dataset_inter.author_id, type:int, comment:null), FieldSchema(name:dataset_inter.bestsellers_rank, type:int, comment:null), FieldSchema(name:dataset_inter.imprint, type:string, comment:null), FieldSchema(name:dataset_inter.publication_date, type:string, comment:null), FieldSchema(name:dataset_inter.rating_avg, type:float, comment:null), FieldSchema(name:dataset_inter.rating_count, type:int, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004802_056d7afd-8355-44fc-b33b-a99b44da1aea); Time taken: 0.098 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004802_056d7afd-8355-44fc-b33b-a99b44da1aea): SELECT * FROM dataset_inter LIMIT 5\n",
      "INFO  : Completed executing command(queryId=root_20211118004802_056d7afd-8355-44fc-b33b-a99b44da1aea); Time taken: 0.001 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------------------------------------------+--------------------------+---------------------------------+------------------------+---------------------------------+---------------------------+-----------------------------+\n",
      "|                dataset_inter.title                 | dataset_inter.author_id  | dataset_inter.bestsellers_rank  | dataset_inter.imprint  | dataset_inter.publication_date  | dataset_inter.rating_avg  | dataset_inter.rating_count  |\n",
      "+----------------------------------------------------+--------------------------+---------------------------------+------------------------+---------------------------------+---------------------------+-----------------------------+\n",
      "| The Mercenary : Order of the Broken Blade          | 3                        | 51517                           |                        | 17/09/2019                      | 4.49                      | 211                         |\n",
      "| 100 Skills You'll Need for the End of the World (as We Know It) | 4                        | 162985                          |                        | 05/05/2015                      | 2.96                      | 139                         |\n",
      "| How to Land a Plane                                | 5                        | 41520                           |                        | 21/09/2017                      | 4.21                      | 158                         |\n",
      "| Skyfaring : A Journey with a Pilot                 | 5                        | 870385                          |                        | 03/05/2016                      | 3.94                      | 2684                        |\n",
      "| How to Land a Plane                                | 5                        | 882451                          |                        | 30/04/2019                      | 4.21                      | 158                         |\n",
      "+----------------------------------------------------+--------------------------+---------------------------------+------------------------+---------------------------------+---------------------------+-----------------------------+\n",
      "5 rows selected (0.211 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM dataset_inter LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos en la tabla definitiva partiendo de la tabla intermedia y modificando el formato de la fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004807_1cf50ab7-fac6-432f-baea-daaf5ad2be4a): INSERT INTO TABLE dataset SELECT title, author_id, bestsellers_rank, imprint, cast(to_date(from_unixtime(unix_timestamp(publication_date, 'dd/MM/yyyy'))) as date) as publication_date, rating_avg, rating_count FROM dataset_inter\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null), FieldSchema(name:author_id, type:int, comment:null), FieldSchema(name:bestsellers_rank, type:int, comment:null), FieldSchema(name:imprint, type:string, comment:null), FieldSchema(name:publication_date, type:date, comment:null), FieldSchema(name:rating_avg, type:float, comment:null), FieldSchema(name:rating_count, type:int, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004807_1cf50ab7-fac6-432f-baea-daaf5ad2be4a); Time taken: 0.645 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004807_1cf50ab7-fac6-432f-baea-daaf5ad2be4a): INSERT INTO TABLE dataset SELECT title, author_id, bestsellers_rank, imprint, cast(to_date(from_unixtime(unix_timestamp(publication_date, 'dd/MM/yyyy'))) as date) as publication_date, rating_avg, rating_count FROM dataset_inter\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118004807_1cf50ab7-fac6-432f-baea-daaf5ad2be4a\n",
      "INFO  : Total jobs = 3\n",
      "INFO  : Launching Job 1 out of 3\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0002\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0002/\n",
      "INFO  : Starting Job = job_1637192506404_0002, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0002/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0002\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2021-11-18 00:48:16,135 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:48:22,305 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.11 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 110 msec\n",
      "INFO  : Ended Job = job_1637192506404_0002\n",
      "INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-4 is selected by condition resolver.\n",
      "INFO  : Stage-3 is filtered out by condition resolver.\n",
      "INFO  : Stage-5 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-4:MOVE] in serial mode\n",
      "INFO  : Moving data to directory hdfs://namenode:8020/user/hive/warehouse/practica.db/dataset/.hive-staging_hive_2021-11-18_00-48-07_747_2208073252343616800-1/-ext-10000 from hdfs://namenode:8020/user/hive/warehouse/practica.db/dataset/.hive-staging_hive_2021-11-18_00-48-07_747_2208073252343616800-1/-ext-10002\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.dataset from hdfs://namenode:8020/user/hive/warehouse/practica.db/dataset/.hive-staging_hive_2021-11-18_00-48-07_747_2208073252343616800-1/-ext-10000\n",
      "INFO  : Starting task [Stage-2:STATS] in serial mode\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1   Cumulative CPU: 5.11 sec   HDFS Read: 3398464 HDFS Write: 3430917 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 5 seconds 110 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118004807_1cf50ab7-fac6-432f-baea-daaf5ad2be4a); Time taken: 15.291 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (15.949 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \" INSERT INTO TABLE dataset \\\n",
    "SELECT title, author_id, bestsellers_rank, imprint, cast(to_date(from_unixtime(unix_timestamp(publication_date, 'dd/MM/yyyy'))) as date) as publication_date, \\\n",
    "rating_avg, rating_count \\\n",
    "FROM dataset_inter;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los datos están cargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004831_10655656-ee2b-4fa3-9ed4-f6b4845bfb6d): SELECT * FROM dataset LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:dataset.title, type:string, comment:null), FieldSchema(name:dataset.author_id, type:int, comment:null), FieldSchema(name:dataset.bestsellers_rank, type:int, comment:null), FieldSchema(name:dataset.imprint, type:string, comment:null), FieldSchema(name:dataset.publication_date, type:date, comment:null), FieldSchema(name:dataset.rating_avg, type:float, comment:null), FieldSchema(name:dataset.rating_count, type:int, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004831_10655656-ee2b-4fa3-9ed4-f6b4845bfb6d); Time taken: 0.118 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004831_10655656-ee2b-4fa3-9ed4-f6b4845bfb6d): SELECT * FROM dataset LIMIT 5\n",
      "INFO  : Completed executing command(queryId=root_20211118004831_10655656-ee2b-4fa3-9ed4-f6b4845bfb6d); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------------------------------------------+--------------------+---------------------------+------------------+---------------------------+---------------------+-----------------------+\n",
      "|                   dataset.title                    | dataset.author_id  | dataset.bestsellers_rank  | dataset.imprint  | dataset.publication_date  | dataset.rating_avg  | dataset.rating_count  |\n",
      "+----------------------------------------------------+--------------------+---------------------------+------------------+---------------------------+---------------------+-----------------------+\n",
      "| 100 Skills You'll Need for the End of the World (as We Know It) | 4                  | 162985                    |                  | 2015-05-05                | 2.96                | 139                   |\n",
      "| How to Land a Plane                                | 5                  | 41520                     |                  | 2017-09-21                | 4.21                | 158                   |\n",
      "| Skyfaring : A Journey with a Pilot                 | 5                  | 870385                    |                  | 2016-05-03                | 3.94                | 2684                  |\n",
      "| How to Land a Plane                                | 5                  | 882451                    |                  | 2019-04-30                | 4.21                | 158                   |\n",
      "| The Sustainable(ish) Living Guide : Everything you need to know to make small changes that make a big difference | 6                  | 3885                      | Green Tree       | 2020-03-10                | 0.0                 | 0                     |\n",
      "+----------------------------------------------------+--------------------+---------------------------+------------------+---------------------------+---------------------+-----------------------+\n",
      "5 rows selected (0.23 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM dataset LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos la tabla intermedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004837_71e215de-de79-4dbc-9a77-8ef6c8f87c4c): DROP TABLE dataset_inter\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004837_71e215de-de79-4dbc-9a77-8ef6c8f87c4c); Time taken: 0.047 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004837_71e215de-de79-4dbc-9a77-8ef6c8f87c4c): DROP TABLE dataset_inter\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004837_71e215de-de79-4dbc-9a77-8ef6c8f87c4c); Time taken: 0.191 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.288 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE dataset_inter;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que están creadas solamente las tablas author y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004842_5157b842-aa4b-4ca0-a9a7-23947237c192): SHOW TABLES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004842_5157b842-aa4b-4ca0-a9a7-23947237c192); Time taken: 0.04 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004842_5157b842-aa4b-4ca0-a9a7-23947237c192): SHOW TABLES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004842_5157b842-aa4b-4ca0-a9a7-23947237c192); Time taken: 0.012 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-----------+\n",
      "| tab_name  |\n",
      "+-----------+\n",
      "| author    |\n",
      "| dataset   |\n",
      "+-----------+\n",
      "2 rows selected (0.138 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"SHOW TABLES;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.3. Crea una vista sobre las tablas creadas\n",
    "\n",
    "Esta vista tendrá para cada título, el nombre del autor, fecha de publicación, y valoración media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004847_1f976787-73fc-4965-89db-4b8fead5fcc7): DROP VIEW dataset_view\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004847_1f976787-73fc-4965-89db-4b8fead5fcc7); Time taken: 0.036 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004847_1f976787-73fc-4965-89db-4b8fead5fcc7): DROP VIEW dataset_view\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004847_1f976787-73fc-4965-89db-4b8fead5fcc7); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.092 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP VIEW dataset_view;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004852_c6009a4b-b200-42d8-865d-c4e3227f65bd): CREATE VIEW dataset_view as SELECT title, author_name, publication_date, rating_avg from author INNER JOIN dataset on author.author_id=dataset.author_id\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null), FieldSchema(name:author_name, type:string, comment:null), FieldSchema(name:publication_date, type:date, comment:null), FieldSchema(name:rating_avg, type:float, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004852_c6009a4b-b200-42d8-865d-c4e3227f65bd); Time taken: 0.228 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004852_c6009a4b-b200-42d8-865d-c4e3227f65bd): CREATE VIEW dataset_view as SELECT title, author_name, publication_date, rating_avg from author INNER JOIN dataset on author.author_id=dataset.author_id\n",
      "INFO  : Starting task [Stage-1:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004852_c6009a4b-b200-42d8-865d-c4e3227f65bd); Time taken: 0.034 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.307 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE VIEW dataset_view as \\\n",
    "SELECT title, author_name, publication_date, rating_avg \\\n",
    "from author INNER JOIN dataset on author.author_id=dataset.author_id;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que la vista se ha creado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004858_6c9bb930-a667-4968-b55a-c771157edd30): show tables\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004858_6c9bb930-a667-4968-b55a-c771157edd30); Time taken: 0.039 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004858_6c9bb930-a667-4968-b55a-c771157edd30): show tables\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118004858_6c9bb930-a667-4968-b55a-c771157edd30); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------+\n",
      "|   tab_name    |\n",
      "+---------------+\n",
      "| author        |\n",
      "| dataset       |\n",
      "| dataset_view  |\n",
      "+---------------+\n",
      "3 rows selected (0.13 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"show tables;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004902_e813bcb7-1442-4245-98e4-35154fcb8fa3): SELECT * FROM dataset_view LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:dataset_view.title, type:string, comment:null), FieldSchema(name:dataset_view.author_name, type:string, comment:null), FieldSchema(name:dataset_view.publication_date, type:date, comment:null), FieldSchema(name:dataset_view.rating_avg, type:float, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004902_e813bcb7-1442-4245-98e4-35154fcb8fa3); Time taken: 0.304 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004902_e813bcb7-1442-4245-98e4-35154fcb8fa3): SELECT * FROM dataset_view LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118004902_e813bcb7-1442-4245-98e4-35154fcb8fa3\n",
      "INFO  : Total jobs = 1\n",
      "INFO  : Starting task [Stage-4:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 1\n",
      "INFO  : Starting task [Stage-3:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0003\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0003/\n",
      "INFO  : Starting Job = job_1637192506404_0003, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0003/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0003\n",
      "INFO  : Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2021-11-18 00:49:13,513 Stage-3 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:49:19,731 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 3.92 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 920 msec\n",
      "INFO  : Ended Job = job_1637192506404_0003\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-3: Map: 1   Cumulative CPU: 3.92 sec   HDFS Read: 711293 HDFS Write: 559 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 3 seconds 920 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118004902_e813bcb7-1442-4245-98e4-35154fcb8fa3); Time taken: 17.608 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------------------------------------------+---------------------------+--------------------------------+--------------------------+\n",
      "|                 dataset_view.title                 | dataset_view.author_name  | dataset_view.publication_date  | dataset_view.rating_avg  |\n",
      "+----------------------------------------------------+---------------------------+--------------------------------+--------------------------+\n",
      "| 100 Skills You'll Need for the End of the World (as We Know It) | Ana Maria Spagna          | 2015-05-05                     | 2.96                     |\n",
      "| How to Land a Plane                                | Mark Vanhoenacker         | 2017-09-21                     | 4.21                     |\n",
      "| Skyfaring : A Journey with a Pilot                 | Mark Vanhoenacker         | 2016-05-03                     | 3.94                     |\n",
      "| How to Land a Plane                                | Mark Vanhoenacker         | 2019-04-30                     | 4.21                     |\n",
      "| The Sustainable(ish) Living Guide : Everything you need to know to make small changes that make a big difference | Jen Gale                  | 2020-03-10                     | 0.0                      |\n",
      "+----------------------------------------------------+---------------------------+--------------------------------+--------------------------+\n",
      "5 rows selected (18.006 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM dataset_view LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.4. Crea las consultas de Hive necesarias para responder las siguientes cuestiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuál es el título del libro con mejor valoración media del autor Rand McNally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118004930_d79e56ef-88f9-4068-863b-90700461b642): SELECT author.author_name, dataset.title, dataset.rating_avg FROM author INNER JOIN dataset ON author.author_id = dataset.author_id and author.author_name = 'Rand McNally' order by dataset.rating_avg DESC LIMIT 1\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:author.author_name, type:string, comment:null), FieldSchema(name:dataset.title, type:string, comment:null), FieldSchema(name:dataset.rating_avg, type:float, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118004930_d79e56ef-88f9-4068-863b-90700461b642); Time taken: 0.251 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118004930_d79e56ef-88f9-4068-863b-90700461b642): SELECT author.author_name, dataset.title, dataset.rating_avg FROM author INNER JOIN dataset ON author.author_id = dataset.author_id and author.author_name = 'Rand McNally' order by dataset.rating_avg DESC LIMIT 1\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118004930_d79e56ef-88f9-4068-863b-90700461b642\n",
      "INFO  : Total jobs = 1\n",
      "INFO  : Starting task [Stage-5:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 1\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0004\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0004/\n",
      "INFO  : Starting Job = job_1637192506404_0004, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0004/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0004\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:49:41,945 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:50:42,168 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:50:43,198 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 8.19 sec\n",
      "INFO  : 2021-11-18 00:50:49,357 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 10.5 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 10 seconds 500 msec\n",
      "INFO  : Ended Job = job_1637192506404_0004\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 10.5 sec   HDFS Read: 3449807 HDFS Write: 157 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 10 seconds 500 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118004930_d79e56ef-88f9-4068-863b-90700461b642); Time taken: 79.749 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+-------------------------------------------+---------------------+\n",
      "| author.author_name  |               dataset.title               | dataset.rating_avg  |\n",
      "+---------------------+-------------------------------------------+---------------------+\n",
      "| Rand McNally        | Delorme South Dakota Atlas and Gazetteer  | 5.0                 |\n",
      "+---------------------+-------------------------------------------+---------------------+\n",
      "1 row selected (80.068 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT author.author_name, dataset.title, dataset.rating_avg FROM author \\\n",
    "INNER JOIN dataset \\\n",
    "ON author.author_id = dataset.author_id and author.author_name = 'Rand McNally' \\\n",
    "order by dataset.rating_avg DESC LIMIT 1;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuáles son los cinco autores cuyos libros tienen más valoraciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005106_393cf066-f5cf-4cd7-85e6-02b920a202b5): SELECT author.author_name, sum(rating_count) as rating_sum FROM author INNER JOIN dataset ON author.author_id = dataset.author_id GROUP BY author.author_name ORDER BY rating_sum DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:author.author_name, type:string, comment:null), FieldSchema(name:rating_sum, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005106_393cf066-f5cf-4cd7-85e6-02b920a202b5); Time taken: 0.226 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005106_393cf066-f5cf-4cd7-85e6-02b920a202b5): SELECT author.author_name, sum(rating_count) as rating_sum FROM author INNER JOIN dataset ON author.author_id = dataset.author_id GROUP BY author.author_name ORDER BY rating_sum DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118005106_393cf066-f5cf-4cd7-85e6-02b920a202b5\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Starting task [Stage-6:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0005\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0005/\n",
      "INFO  : Starting Job = job_1637192506404_0005, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0005/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0005\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:51:16,907 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:51:23,062 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.21 sec\n",
      "INFO  : 2021-11-18 00:51:27,186 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.42 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 7 seconds 420 msec\n",
      "INFO  : Ended Job = job_1637192506404_0005\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-3:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0006\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0006/\n",
      "INFO  : Starting Job = job_1637192506404_0006, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0006/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0006\n",
      "INFO  : Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:51:33,965 Stage-3 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:51:39,155 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec\n",
      "INFO  : 2021-11-18 00:51:45,314 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.28 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 280 msec\n",
      "INFO  : Ended Job = job_1637192506404_0006\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.42 sec   HDFS Read: 3450339 HDFS Write: 696582 SUCCESS\n",
      "INFO  : Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.28 sec   HDFS Read: 704291 HDFS Write: 274 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 11 seconds 700 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118005106_393cf066-f5cf-4cd7-85e6-02b920a202b5); Time taken: 39.374 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------------+-------------+\n",
      "|    author.author_name     | rating_sum  |\n",
      "+---------------------------+-------------+\n",
      "| J. K. Rowling             | 4863194     |\n",
      "| Clive Staples Lewis       | 1949632     |\n",
      "| Antoine de Saint-Exupery  | 1109468     |\n",
      "| Charles Dickens           | 560369      |\n",
      "| James Herriot             | 322950      |\n",
      "+---------------------------+-------------+\n",
      "5 rows selected (39.656 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \" SELECT author.author_name, sum(rating_count) as rating_sum FROM author \\\n",
    "INNER JOIN dataset \\\n",
    "ON author.author_id = dataset.author_id \\\n",
    "GROUP BY author.author_name \\\n",
    "ORDER BY rating_sum DESC LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cuáles son los dos libros más recientes del autor Rand McNally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005156_663ea8e6-1311-417f-8b73-55ca68d752d7): SELECT title, publication_date FROM author INNER JOIN dataset ON author.author_id = dataset.author_id AND author.author_name = 'Rand McNally' ORDER BY publication_date DESC LIMIT 2\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:title, type:string, comment:null), FieldSchema(name:publication_date, type:date, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005156_663ea8e6-1311-417f-8b73-55ca68d752d7); Time taken: 0.221 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005156_663ea8e6-1311-417f-8b73-55ca68d752d7): SELECT title, publication_date FROM author INNER JOIN dataset ON author.author_id = dataset.author_id AND author.author_name = 'Rand McNally' ORDER BY publication_date DESC LIMIT 2\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118005156_663ea8e6-1311-417f-8b73-55ca68d752d7\n",
      "INFO  : Total jobs = 1\n",
      "INFO  : Starting task [Stage-5:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 1\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0007\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0007/\n",
      "INFO  : Starting Job = job_1637192506404_0007, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0007/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0007\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:52:06,150 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:52:11,299 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.77 sec\n",
      "INFO  : 2021-11-18 00:52:16,433 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 980 msec\n",
      "INFO  : Ended Job = job_1637192506404_0007\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.98 sec   HDFS Read: 3449297 HDFS Write: 230 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 5 seconds 980 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118005156_663ea8e6-1311-417f-8b73-55ca68d752d7); Time taken: 21.098 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------------------------------------------+-------------------+\n",
      "|                       title                        | publication_date  |\n",
      "+----------------------------------------------------+-------------------+\n",
      "| Rand McNally 2021 Motor Carriers' Road Atlas       | 2020-06-22        |\n",
      "| Rand McNally 2021 Deluxe Motor Carriers' Road Atlas | 2020-06-22        |\n",
      "+----------------------------------------------------+-------------------+\n",
      "2 rows selected (21.371 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \" SELECT title, publication_date FROM author \\\n",
    "INNER JOIN dataset \\\n",
    "ON author.author_id = dataset.author_id AND author.author_name = 'Rand McNally' \\\n",
    "ORDER BY publication_date DESC \\\n",
    "LIMIT 2;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.5. Selecciona un dataset, impórtalo en las tablas de Hive necesarias e implementa al menos dos consultas sobre dicho dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte del ejercicio práctico se ha escogido el dataset FIFA World Cup que contiene información sobre la Copa Mundial de Fútbol desde la primera edición del año 1930 hasta la edición del 2014. Los ficheros que se pretenden cargar almacenan los datos de las ediciones de la Copa Mundial, de todos los partidos disputados y de los jugadores participantes. \n",
    "\n",
    "Las preguntas que se desean contestar están relacionadas con la estadística y con la cultura general que forma parte del torneo. \n",
    "\n",
    "El dataset se encuentra en el enlace https://www.kaggle.com/abecklas/fifa-world-cup, donde se puede encontrar más información sobre él. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera parte. Creación de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005256_0f6fd6b6-c67c-4141-b37b-f68953f6d51b): DROP TABLE worldcups\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005256_0f6fd6b6-c67c-4141-b37b-f68953f6d51b); Time taken: 0.036 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005256_0f6fd6b6-c67c-4141-b37b-f68953f6d51b): DROP TABLE worldcups\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005256_0f6fd6b6-c67c-4141-b37b-f68953f6d51b); Time taken: 0.009 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.087 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE worldcups;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005306_5168024b-7fd7-4d9c-ad8f-7255699b3298): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005306_5168024b-7fd7-4d9c-ad8f-7255699b3298); Time taken: 0.053 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005306_5168024b-7fd7-4d9c-ad8f-7255699b3298): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005306_5168024b-7fd7-4d9c-ad8f-7255699b3298); Time taken: 0.008 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.097 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118005306_c782525d-a44e-439e-8ca0-6fecadd237db): CREATE TABLE IF NOT EXISTS worldcups(year INT, country STRING, winner STRING, runners_up STRING, thrid STRING, fourth STRING, goalsscored INT, qualifiedteams INT, matchesplayed INT, attendance INT) COMMENT 'Copas del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005306_c782525d-a44e-439e-8ca0-6fecadd237db); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005306_c782525d-a44e-439e-8ca0-6fecadd237db): CREATE TABLE IF NOT EXISTS worldcups(year INT, country STRING, winner STRING, runners_up STRING, thrid STRING, fourth STRING, goalsscored INT, qualifiedteams INT, matchesplayed INT, attendance INT) COMMENT 'Copas del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005306_c782525d-a44e-439e-8ca0-6fecadd237db); Time taken: 0.033 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.058 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS worldcups(year INT, country STRING, winner STRING, runners_up STRING, \\\n",
    "thrid STRING, fourth STRING, goalsscored INT, qualifiedteams INT, matchesplayed INT, attendance INT) \\\n",
    "COMMENT 'Copas del mundo con su informacion' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005312_4672a981-e5e0-43a2-b68f-e6429c621862): DROP TABLE matches\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005312_4672a981-e5e0-43a2-b68f-e6429c621862); Time taken: 0.032 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005312_4672a981-e5e0-43a2-b68f-e6429c621862): DROP TABLE matches\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005312_4672a981-e5e0-43a2-b68f-e6429c621862); Time taken: 0.008 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.078 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE matches;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005316_ee1763ff-f25e-45e3-88f8-b37ba1f4f1db): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005316_ee1763ff-f25e-45e3-88f8-b37ba1f4f1db); Time taken: 0.042 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005316_ee1763ff-f25e-45e3-88f8-b37ba1f4f1db): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005316_ee1763ff-f25e-45e3-88f8-b37ba1f4f1db); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.087 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118005316_74abd5ce-d21e-4ba6-a8c5-508d64728ea9): CREATE TABLE IF NOT EXISTS matches (year INT, datetime STRING, stage STRING, stadium STRING, city STRING, home_team STRING, home_goals INT, away_goals INT, away_team STRING, win_conditions STRING, attendance INT, home_goals_ht INT, away_goals_ht INT, referee STRING, assitant_one STRING, assistant_two STRING, round_id INT, match_id INT, home_team_initials STRING, away_team_initials STRING) COMMENT 'Partidos de la copa del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005316_74abd5ce-d21e-4ba6-a8c5-508d64728ea9); Time taken: 0.016 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005316_74abd5ce-d21e-4ba6-a8c5-508d64728ea9): CREATE TABLE IF NOT EXISTS matches (year INT, datetime STRING, stage STRING, stadium STRING, city STRING, home_team STRING, home_goals INT, away_goals INT, away_team STRING, win_conditions STRING, attendance INT, home_goals_ht INT, away_goals_ht INT, referee STRING, assitant_one STRING, assistant_two STRING, round_id INT, match_id INT, home_team_initials STRING, away_team_initials STRING) COMMENT 'Partidos de la copa del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005316_74abd5ce-d21e-4ba6-a8c5-508d64728ea9); Time taken: 0.063 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.084 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS matches \\\n",
    "(year INT, datetime STRING, stage STRING, stadium STRING, city STRING, home_team STRING, home_goals INT, \\\n",
    "away_goals INT, away_team STRING, win_conditions STRING, attendance INT, home_goals_ht INT, away_goals_ht INT, \\\n",
    "referee STRING, assitant_one STRING, assistant_two STRING, round_id INT, match_id INT, \\\n",
    "home_team_initials STRING, away_team_initials STRING) \\\n",
    "COMMENT 'Partidos de la copa del mundo con su informacion' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005323_b4f80df2-57a4-4ab0-9cfb-5357c6769772): DROP TABLE players\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005323_b4f80df2-57a4-4ab0-9cfb-5357c6769772); Time taken: 0.031 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005323_b4f80df2-57a4-4ab0-9cfb-5357c6769772): DROP TABLE players\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005323_b4f80df2-57a4-4ab0-9cfb-5357c6769772); Time taken: 0.008 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.084 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"DROP TABLE players;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005327_ac29cd55-5dc9-4697-bcec-ef64cd5f5946): USE practica\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005327_ac29cd55-5dc9-4697-bcec-ef64cd5f5946); Time taken: 0.029 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005327_ac29cd55-5dc9-4697-bcec-ef64cd5f5946): USE practica\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005327_ac29cd55-5dc9-4697-bcec-ef64cd5f5946); Time taken: 0.01 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.08 seconds)\n",
      "INFO  : Compiling command(queryId=root_20211118005327_c9422a10-6765-4beb-a5d3-daefe1dcb7df): CREATE TABLE IF NOT EXISTS players (round_id INT, match_id INT, team_initials STRING, coach STRING, line_up VARCHAR(1), shirt_number TINYINT, player STRING, position VARCHAR(2), event STRING) COMMENT 'Jugadores de la copa del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005327_c9422a10-6765-4beb-a5d3-daefe1dcb7df); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005327_c9422a10-6765-4beb-a5d3-daefe1dcb7df): CREATE TABLE IF NOT EXISTS players (round_id INT, match_id INT, team_initials STRING, coach STRING, line_up VARCHAR(1), shirt_number TINYINT, player STRING, position VARCHAR(2), event STRING) COMMENT 'Jugadores de la copa del mundo con su informacion' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005327_c9422a10-6765-4beb-a5d3-daefe1dcb7df); Time taken: 0.037 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.062 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"CREATE TABLE IF NOT EXISTS players \\\n",
    "(round_id INT, match_id INT, team_initials STRING, coach STRING, line_up VARCHAR(1), \\\n",
    "shirt_number TINYINT, player STRING, position VARCHAR(2), event STRING) \\\n",
    "COMMENT 'Jugadores de la copa del mundo con su informacion' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Bigdata', 'Fecha' = '09/11/21', 'skip.header.line.count'='1');\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/\" -e \"USE practica; {sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que las tablas se han creado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005332_ac289303-d2cf-4009-aa0f-7c06ff035cb2): SHOW TABLES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005332_ac289303-d2cf-4009-aa0f-7c06ff035cb2); Time taken: 0.036 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005332_ac289303-d2cf-4009-aa0f-7c06ff035cb2): SHOW TABLES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005332_ac289303-d2cf-4009-aa0f-7c06ff035cb2); Time taken: 0.018 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------+\n",
      "|   tab_name    |\n",
      "+---------------+\n",
      "| author        |\n",
      "| dataset       |\n",
      "| dataset_view  |\n",
      "| matches       |\n",
      "| players       |\n",
      "| worldcups     |\n",
      "+---------------+\n",
      "6 rows selected (0.118 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SHOW TABLES;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiamos los archivos csv a Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal WorldCups.csv /user/root/\n",
    "!hadoop fs -copyFromLocal WorldCupMatches.csv /user/root/\n",
    "!hadoop fs -copyFromLocal WorldCupPlayers.csv /user/root/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos desde los archivos csv a las tablas creadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005345_249a1369-53a7-48a2-a954-2c9b5aefa3a3): LOAD DATA INPATH 'WorldCups.csv' INTO TABLE worldcups\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005345_249a1369-53a7-48a2-a954-2c9b5aefa3a3); Time taken: 0.057 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005345_249a1369-53a7-48a2-a954-2c9b5aefa3a3): LOAD DATA INPATH 'WorldCups.csv' INTO TABLE worldcups\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.worldcups from hdfs://namenode:8020/user/root/WorldCups.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005345_249a1369-53a7-48a2-a954-2c9b5aefa3a3); Time taken: 0.113 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.226 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"LOAD DATA INPATH 'WorldCups.csv' INTO TABLE worldcups;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005349_066097c9-8225-4b73-9928-bb156aa47ce4): LOAD DATA INPATH 'WorldCupMatches.csv' INTO TABLE matches\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005349_066097c9-8225-4b73-9928-bb156aa47ce4); Time taken: 0.058 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005349_066097c9-8225-4b73-9928-bb156aa47ce4): LOAD DATA INPATH 'WorldCupMatches.csv' INTO TABLE matches\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.matches from hdfs://namenode:8020/user/root/WorldCupMatches.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005349_066097c9-8225-4b73-9928-bb156aa47ce4); Time taken: 0.108 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.206 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"LOAD DATA INPATH 'WorldCupMatches.csv' INTO TABLE matches;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005354_69a8d693-ebe2-41a1-9f16-669f68bdc27c): LOAD DATA INPATH 'WorldCupPlayers.csv' INTO TABLE players\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005354_69a8d693-ebe2-41a1-9f16-669f68bdc27c); Time taken: 0.043 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005354_69a8d693-ebe2-41a1-9f16-669f68bdc27c): LOAD DATA INPATH 'WorldCupPlayers.csv' INTO TABLE players\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table practica.players from hdfs://namenode:8020/user/root/WorldCupPlayers.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20211118005354_69a8d693-ebe2-41a1-9f16-669f68bdc27c); Time taken: 0.124 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.213 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"LOAD DATA INPATH 'WorldCupPlayers.csv' INTO TABLE players;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement};\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los datos se han cargado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005359_d897addb-00ca-498c-996a-bba27999475a): SELECT * FROM worldcups LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:worldcups.year, type:int, comment:null), FieldSchema(name:worldcups.country, type:string, comment:null), FieldSchema(name:worldcups.winner, type:string, comment:null), FieldSchema(name:worldcups.runners_up, type:string, comment:null), FieldSchema(name:worldcups.thrid, type:string, comment:null), FieldSchema(name:worldcups.fourth, type:string, comment:null), FieldSchema(name:worldcups.goalsscored, type:int, comment:null), FieldSchema(name:worldcups.qualifiedteams, type:int, comment:null), FieldSchema(name:worldcups.matchesplayed, type:int, comment:null), FieldSchema(name:worldcups.attendance, type:int, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005359_d897addb-00ca-498c-996a-bba27999475a); Time taken: 0.105 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005359_d897addb-00ca-498c-996a-bba27999475a): SELECT * FROM worldcups LIMIT 5\n",
      "INFO  : Completed executing command(queryId=root_20211118005359_d897addb-00ca-498c-996a-bba27999475a); Time taken: 0.001 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-----------------+--------------------+-------------------+-----------------------+------------------+-------------------+------------------------+---------------------------+--------------------------+-----------------------+\n",
      "| worldcups.year  | worldcups.country  | worldcups.winner  | worldcups.runners_up  | worldcups.thrid  | worldcups.fourth  | worldcups.goalsscored  | worldcups.qualifiedteams  | worldcups.matchesplayed  | worldcups.attendance  |\n",
      "+-----------------+--------------------+-------------------+-----------------------+------------------+-------------------+------------------------+---------------------------+--------------------------+-----------------------+\n",
      "| 1930            | Uruguay            | Uruguay           | Argentina             | USA              | Yugoslavia        | 70                     | 13                        | 18                       | 590                   |\n",
      "| 1934            | Italy              | Italy             | Czechoslovakia        | Germany          | Austria           | 70                     | 16                        | 17                       | 363                   |\n",
      "| 1938            | France             | Italy             | Hungary               | Brazil           | Sweden            | 84                     | 15                        | 18                       | 375                   |\n",
      "| 1950            | Brazil             | Uruguay           | Brazil                | Sweden           | Spain             | 88                     | 13                        | 22                       | NULL                  |\n",
      "| 1954            | Switzerland        | Germany FR        | Hungary               | Austria          | Uruguay           | 140                    | 16                        | 26                       | 768                   |\n",
      "+-----------------+--------------------+-------------------+-----------------------+------------------+-------------------+------------------------+---------------------------+--------------------------+-----------------------+\n",
      "5 rows selected (0.197 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM worldcups LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005406_7190bf1a-f94f-4944-84dd-68a1ac210613): SELECT * FROM matches LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:matches.year, type:int, comment:null), FieldSchema(name:matches.datetime, type:string, comment:null), FieldSchema(name:matches.stage, type:string, comment:null), FieldSchema(name:matches.stadium, type:string, comment:null), FieldSchema(name:matches.city, type:string, comment:null), FieldSchema(name:matches.home_team, type:string, comment:null), FieldSchema(name:matches.home_goals, type:int, comment:null), FieldSchema(name:matches.away_goals, type:int, comment:null), FieldSchema(name:matches.away_team, type:string, comment:null), FieldSchema(name:matches.win_conditions, type:string, comment:null), FieldSchema(name:matches.attendance, type:int, comment:null), FieldSchema(name:matches.home_goals_ht, type:int, comment:null), FieldSchema(name:matches.away_goals_ht, type:int, comment:null), FieldSchema(name:matches.referee, type:string, comment:null), FieldSchema(name:matches.assitant_one, type:string, comment:null), FieldSchema(name:matches.assistant_two, type:string, comment:null), FieldSchema(name:matches.round_id, type:int, comment:null), FieldSchema(name:matches.match_id, type:int, comment:null), FieldSchema(name:matches.home_team_initials, type:string, comment:null), FieldSchema(name:matches.away_team_initials, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005406_7190bf1a-f94f-4944-84dd-68a1ac210613); Time taken: 0.105 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005406_7190bf1a-f94f-4944-84dd-68a1ac210613): SELECT * FROM matches LIMIT 5\n",
      "INFO  : Completed executing command(queryId=root_20211118005406_7190bf1a-f94f-4944-84dd-68a1ac210613); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------+-------------------------+----------------+------------------+----------------+--------------------+---------------------+---------------------+--------------------+-------------------------+---------------------+------------------------+------------------------+-------------------------+---------------------------+-----------------------------+-------------------+-------------------+-----------------------------+-----------------------------+\n",
      "| matches.year  |    matches.datetime     | matches.stage  | matches.stadium  |  matches.city  | matches.home_team  | matches.home_goals  | matches.away_goals  | matches.away_team  | matches.win_conditions  | matches.attendance  | matches.home_goals_ht  | matches.away_goals_ht  |     matches.referee     |   matches.assitant_one    |    matches.assistant_two    | matches.round_id  | matches.match_id  | matches.home_team_initials  | matches.away_team_initials  |\n",
      "+---------------+-------------------------+----------------+------------------+----------------+--------------------+---------------------+---------------------+--------------------+-------------------------+---------------------+------------------------+------------------------+-------------------------+---------------------------+-----------------------------+-------------------+-------------------+-----------------------------+-----------------------------+\n",
      "| 1930          | \"13 Jul 1930 - 15:00 \"  | Group 1        | Pocitos          | \"Montevideo \"  | France             | 4                   | 1                   | Mexico             | \" \"                     | 4444                | 3                      | 0                      | LOMBARDI Domingo (URU)  | CRISTOPHE Henry (BEL)     | REGO Gilberto (BRA)         | 201               | 1096              | FRA                         | MEX                         |\n",
      "| 1930          | \"13 Jul 1930 - 15:00 \"  | Group 4        | Parque Central   | \"Montevideo \"  | USA                | 3                   | 0                   | Belgium            | \" \"                     | 18346               | 2                      | 0                      | MACIAS Jose (ARG)       | MATEUCCI Francisco (URU)  | WARNKEN Alberto (CHI)       | 201               | 1090              | USA                         | BEL                         |\n",
      "| 1930          | \"14 Jul 1930 - 12:45 \"  | Group 2        | Parque Central   | \"Montevideo \"  | Yugoslavia         | 2                   | 1                   | Brazil             | \" \"                     | 24059               | 2                      | 0                      | TEJADA Anibal (URU)     | VALLARINO Ricardo (URU)   | BALWAY Thomas (FRA)         | 201               | 1093              | YUG                         | BRA                         |\n",
      "| 1930          | \"14 Jul 1930 - 14:50 \"  | Group 3        | Pocitos          | \"Montevideo \"  | Romania            | 3                   | 1                   | Peru               | \" \"                     | 2549                | 1                      | 0                      | WARNKEN Alberto (CHI)   | LANGENUS Jean (BEL)       | MATEUCCI Francisco (URU)    | 201               | 1098              | ROU                         | PER                         |\n",
      "| 1930          | \"15 Jul 1930 - 16:00 \"  | Group 1        | Parque Central   | \"Montevideo \"  | Argentina          | 1                   | 0                   | France             | \" \"                     | 23409               | 0                      | 0                      | REGO Gilberto (BRA)     | SAUCEDO Ulises (BOL)      | RADULESCU Constantin (ROU)  | 201               | 1085              | ARG                         | FRA                         |\n",
      "+---------------+-------------------------+----------------+------------------+----------------+--------------------+---------------------+---------------------+--------------------+-------------------------+---------------------+------------------------+------------------------+-------------------------+---------------------------+-----------------------------+-------------------+-------------------+-----------------------------+-----------------------------+\n",
      "5 rows selected (0.186 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM matches LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005413_0bc1c604-6765-4a19-a822-660ca154b24f): SELECT * FROM players LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:players.round_id, type:int, comment:null), FieldSchema(name:players.match_id, type:int, comment:null), FieldSchema(name:players.team_initials, type:string, comment:null), FieldSchema(name:players.coach, type:string, comment:null), FieldSchema(name:players.line_up, type:varchar(1), comment:null), FieldSchema(name:players.shirt_number, type:tinyint, comment:null), FieldSchema(name:players.player, type:string, comment:null), FieldSchema(name:players.position, type:varchar(2), comment:null), FieldSchema(name:players.event, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005413_0bc1c604-6765-4a19-a822-660ca154b24f); Time taken: 0.101 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005413_0bc1c604-6765-4a19-a822-660ca154b24f): SELECT * FROM players LIMIT 5\n",
      "INFO  : Completed executing command(queryId=root_20211118005413_0bc1c604-6765-4a19-a822-660ca154b24f); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-------------------+-------------------+------------------------+----------------------+------------------+-----------------------+-------------------+-------------------+----------------+\n",
      "| players.round_id  | players.match_id  | players.team_initials  |    players.coach     | players.line_up  | players.shirt_number  |  players.player   | players.position  | players.event  |\n",
      "+-------------------+-------------------+------------------------+----------------------+------------------+-----------------------+-------------------+-------------------+----------------+\n",
      "| 201               | 1096              | FRA                    | CAUDRON Raoul (FRA)  | S                | 0                     | Alex THEPOT       | GK                |                |\n",
      "| 201               | 1096              | MEX                    | LUQUE Juan (MEX)     | S                | 0                     | Oscar BONFIGLIO   | GK                |                |\n",
      "| 201               | 1096              | FRA                    | CAUDRON Raoul (FRA)  | S                | 0                     | Marcel LANGILLER  |                   | G40'           |\n",
      "| 201               | 1096              | MEX                    | LUQUE Juan (MEX)     | S                | 0                     | Juan CARRENO      |                   | G70'           |\n",
      "| 201               | 1096              | FRA                    | CAUDRON Raoul (FRA)  | S                | 0                     | Ernest LIBERATI   |                   |                |\n",
      "+-------------------+-------------------+------------------------+----------------------+------------------+-----------------------+-------------------+-------------------+----------------+\n",
      "5 rows selected (0.197 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT * FROM players LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda parte. Creación de consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Países que más veces han perdido una final de la Copa del Mundo (1930-2014) sin haberla ganado nunca, ordenados de mayor a menor subcampeonatos.\n",
    "\n",
    "Primero tenemos que obtener la lista de países que aparecen como subcampeones (runners_up) y que no aparecen como ganadores (winner). El resultado de la consulta lo guardamos en una tabla temporal \"not_winners\". \n",
    "Una vez que tenemos la lista de los no ganadores hacemos un INNER JOIN con la propia tabla, utilizando como clave de unión el nombre del país. Seguidamente, agrupamos los resultados por el nombre del país para poder realizar una operación COUNT que calcula cuántas veces cada país ha sido subcampeón. Por último, ordenamos la lista en base a este criterio de mayor a menor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005437_fa454192-d3df-4eab-b174-dd70155b4e71): SELECT runners_up, count(*) as count FROM worldcups INNER JOIN (SELECT DISTINCT runners_up FROM worldcups a WHERE runners_up NOT IN (SELECT DISTINCT winner FROM worldcups)) AS not_winners ON worldcups.runners_up = not_winners.runners_up GROUP BY worldcups.runners_up ORDER BY count DESC\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Warning: Map Join MAPJOIN[82][bigTable=?] in task 'Stage-13:MAPRED' is a cross product\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:runners_up, type:string, comment:null), FieldSchema(name:count, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005437_fa454192-d3df-4eab-b174-dd70155b4e71); Time taken: 0.426 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005437_fa454192-d3df-4eab-b174-dd70155b4e71): SELECT runners_up, count(*) as count FROM worldcups INNER JOIN (SELECT DISTINCT runners_up FROM worldcups a WHERE runners_up NOT IN (SELECT DISTINCT winner FROM worldcups)) AS not_winners ON worldcups.runners_up = not_winners.runners_up GROUP BY worldcups.runners_up ORDER BY count DESC\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118005437_fa454192-d3df-4eab-b174-dd70155b4e71\n",
      "INFO  : Total jobs = 10\n",
      "INFO  : Launching Job 1 out of 10\n",
      "INFO  : Starting task [Stage-6:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0008\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0008/\n",
      "INFO  : Starting Job = job_1637192506404_0008, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0008/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0008\n",
      "INFO  : Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:54:42,900 Stage-6 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:54:47,010 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec\n",
      "INFO  : 2021-11-18 00:54:52,146 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 3.89 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 890 msec\n",
      "INFO  : Ended Job = job_1637192506404_0008\n",
      "INFO  : Launching Job 2 out of 10\n",
      "INFO  : Starting task [Stage-8:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0009\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0009/\n",
      "INFO  : Starting Job = job_1637192506404_0009, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0009/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0009\n",
      "INFO  : Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:54:58,739 Stage-8 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:55:03,863 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 2.49 sec\n",
      "INFO  : 2021-11-18 00:55:09,996 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 4.35 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 350 msec\n",
      "INFO  : Ended Job = job_1637192506404_0009\n",
      "INFO  : Launching Job 3 out of 10\n",
      "INFO  : Starting task [Stage-7:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0010\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0010/\n",
      "INFO  : Starting Job = job_1637192506404_0010, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0010/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0010\n",
      "INFO  : Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:55:16,653 Stage-7 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:55:21,839 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 1.63 sec\n",
      "INFO  : 2021-11-18 00:55:26,947 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 3.37 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 370 msec\n",
      "INFO  : Ended Job = job_1637192506404_0010\n",
      "INFO  : Starting task [Stage-16:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 4 out of 10\n",
      "INFO  : Starting task [Stage-13:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0011\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0011/\n",
      "INFO  : Starting Job = job_1637192506404_0011, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0011/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0011\n",
      "INFO  : Hadoop job information for Stage-13: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2021-11-18 00:55:38,820 Stage-13 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:55:44,959 Stage-13 map = 100%,  reduce = 0%, Cumulative CPU 1.91 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 1 seconds 910 msec\n",
      "INFO  : Ended Job = job_1637192506404_0011\n",
      "INFO  : Starting task [Stage-12:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-15 is selected by condition resolver.\n",
      "INFO  : Stage-5 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-15:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 6 out of 10\n",
      "INFO  : Starting task [Stage-11:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0012\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0012/\n",
      "INFO  : Starting Job = job_1637192506404_0012, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0012/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0012\n",
      "INFO  : Hadoop job information for Stage-11: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2021-11-18 00:55:55,266 Stage-11 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:55:59,367 Stage-11 map = 100%,  reduce = 0%, Cumulative CPU 2.63 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 630 msec\n",
      "INFO  : Ended Job = job_1637192506404_0012\n",
      "INFO  : Starting task [Stage-10:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-14 is selected by condition resolver.\n",
      "INFO  : Stage-1 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-14:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 8 out of 10\n",
      "INFO  : Starting task [Stage-9:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0013\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0013/\n",
      "INFO  : Starting Job = job_1637192506404_0013, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0013/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0013\n",
      "INFO  : Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 0\n",
      "INFO  : 2021-11-18 00:56:09,605 Stage-9 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:56:15,770 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 2.47 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 470 msec\n",
      "INFO  : Ended Job = job_1637192506404_0013\n",
      "INFO  : Launching Job 9 out of 10\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0014\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0014/\n",
      "INFO  : Starting Job = job_1637192506404_0014, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0014/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0014\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:56:22,560 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:56:26,656 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.35 sec\n",
      "INFO  : 2021-11-18 00:56:32,810 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.92 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 920 msec\n",
      "INFO  : Ended Job = job_1637192506404_0014\n",
      "INFO  : Launching Job 10 out of 10\n",
      "INFO  : Starting task [Stage-3:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0015\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0015/\n",
      "INFO  : Starting Job = job_1637192506404_0015, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0015/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0015\n",
      "INFO  : Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:56:39,607 Stage-3 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:56:44,750 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.92 sec\n",
      "INFO  : 2021-11-18 00:56:49,873 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 3.56 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 560 msec\n",
      "INFO  : Ended Job = job_1637192506404_0015\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 3.89 sec   HDFS Read: 14468 HDFS Write: 115 SUCCESS\n",
      "INFO  : Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 4.35 sec   HDFS Read: 14439 HDFS Write: 329 SUCCESS\n",
      "INFO  : Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 3.37 sec   HDFS Read: 6585 HDFS Write: 115 SUCCESS\n",
      "INFO  : Stage-Stage-13: Map: 1   Cumulative CPU: 1.91 sec   HDFS Read: 6826 HDFS Write: 669 SUCCESS\n",
      "INFO  : Stage-Stage-11: Map: 1   Cumulative CPU: 2.63 sec   HDFS Read: 9050 HDFS Write: 206 SUCCESS\n",
      "INFO  : Stage-Stage-9: Map: 1   Cumulative CPU: 2.47 sec   HDFS Read: 11970 HDFS Write: 210 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.92 sec   HDFS Read: 6870 HDFS Write: 210 SUCCESS\n",
      "INFO  : Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 3.56 sec   HDFS Read: 7680 HDFS Write: 185 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 25 seconds 100 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118005437_fa454192-d3df-4eab-b174-dd70155b4e71); Time taken: 133.502 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+-----------------+--------+\n",
      "|   runners_up    | count  |\n",
      "+-----------------+--------+\n",
      "| Netherlands     | 3      |\n",
      "| Hungary         | 2      |\n",
      "| Czechoslovakia  | 2      |\n",
      "| Sweden          | 1      |\n",
      "+-----------------+--------+\n",
      "4 rows selected (133.995 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT runners_up, count(*) as count \\\n",
    "FROM worldcups INNER JOIN \\\n",
    "(SELECT DISTINCT runners_up FROM worldcups a \\\n",
    "WHERE runners_up NOT IN (SELECT DISTINCT winner FROM worldcups)) AS not_winners \\\n",
    "ON worldcups.runners_up = not_winners.runners_up \\\n",
    "GROUP BY worldcups.runners_up \\\n",
    "ORDER BY count DESC;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de goles por partidos jugados en cada Copa del Mundo (1930-2014) en orden cronológico.\n",
    "\n",
    "Hay que realizar una división entre el número de goles marcados, goalsscored, y el número de partidos jugados, matchesplayed. Como el resultado de esta división posiblemente sea un número decimal lo convertimos utilizando la función CAST. Establecemos 4 decimales para obtener un resultado más preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118005925_99ef002b-70c6-466b-a211-b7035ab90926): SELECT country, year, qualifiedteams, goalsscored, matchesplayed, cast(goalsscored/matchesplayed as decimal(6, 4)) as goals_matches FROM worldcups ORDER BY year\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:country, type:string, comment:null), FieldSchema(name:year, type:int, comment:null), FieldSchema(name:qualifiedteams, type:int, comment:null), FieldSchema(name:goalsscored, type:int, comment:null), FieldSchema(name:matchesplayed, type:int, comment:null), FieldSchema(name:goals_matches, type:decimal(6,4), comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118005925_99ef002b-70c6-466b-a211-b7035ab90926); Time taken: 0.114 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118005925_99ef002b-70c6-466b-a211-b7035ab90926): SELECT country, year, qualifiedteams, goalsscored, matchesplayed, cast(goalsscored/matchesplayed as decimal(6, 4)) as goals_matches FROM worldcups ORDER BY year\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118005925_99ef002b-70c6-466b-a211-b7035ab90926\n",
      "INFO  : Total jobs = 1\n",
      "INFO  : Launching Job 1 out of 1\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0018\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0018/\n",
      "INFO  : Starting Job = job_1637192506404_0018, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0018/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0018\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 00:59:31,695 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 00:59:36,857 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.04 sec\n",
      "INFO  : 2021-11-18 00:59:43,008 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.22 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 220 msec\n",
      "INFO  : Ended Job = job_1637192506404_0018\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.22 sec   HDFS Read: 16553 HDFS Write: 915 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 4 seconds 220 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118005925_99ef002b-70c6-466b-a211-b7035ab90926); Time taken: 18.069 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------+-------+-----------------+--------------+----------------+----------------+\n",
      "|    country    | year  | qualifiedteams  | goalsscored  | matchesplayed  | goals_matches  |\n",
      "+---------------+-------+-----------------+--------------+----------------+----------------+\n",
      "| Uruguay       | 1930  | 13              | 70           | 18             | 3.8889         |\n",
      "| Italy         | 1934  | 16              | 70           | 17             | 4.1176         |\n",
      "| France        | 1938  | 15              | 84           | 18             | 4.6667         |\n",
      "| Brazil        | 1950  | 13              | 88           | 22             | 4.0000         |\n",
      "| Switzerland   | 1954  | 16              | 140          | 26             | 5.3846         |\n",
      "| Sweden        | 1958  | 16              | 126          | 35             | 3.6000         |\n",
      "| Chile         | 1962  | 16              | 89           | 32             | 2.7813         |\n",
      "| England       | 1966  | 16              | 89           | 32             | 2.7813         |\n",
      "| Mexico        | 1970  | 16              | 95           | 32             | 2.9688         |\n",
      "| Germany       | 1974  | 16              | 97           | 38             | 2.5526         |\n",
      "| Argentina     | 1978  | 16              | 102          | 38             | 2.6842         |\n",
      "| Spain         | 1982  | 24              | 146          | 52             | 2.8077         |\n",
      "| Mexico        | 1986  | 24              | 132          | 52             | 2.5385         |\n",
      "| Italy         | 1990  | 24              | 115          | 52             | 2.2115         |\n",
      "| USA           | 1994  | 24              | 141          | 52             | 2.7115         |\n",
      "| France        | 1998  | 32              | 171          | 64             | 2.6719         |\n",
      "| Korea/Japan   | 2002  | 32              | 161          | 64             | 2.5156         |\n",
      "| Germany       | 2006  | 32              | 147          | 64             | 2.2969         |\n",
      "| South Africa  | 2010  | 32              | 145          | 64             | 2.2656         |\n",
      "| Brazil        | 2014  | 32              | 171          | 64             | 2.6719         |\n",
      "+---------------+-------+-----------------+--------------+----------------+----------------+\n",
      "20 rows selected (18.25 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT country, year, qualifiedteams, goalsscored, matchesplayed, \\\n",
    "cast(goalsscored/matchesplayed as decimal(6, 4)) as goals_matches \\\n",
    "FROM worldcups \\\n",
    "ORDER BY year;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cinco jugadores que más partidos ha ganado jugando, es decir, siendo titulares o saliendo desde el banquillo. \n",
    "\n",
    "Primero, se obtienen los jugadores que han sido titulares, line_up toma el valor 'S', o han jugado después de comenzar el partido, en el campo event se busca el caracter 'I'. Seguidamente, se obtienen los equipos ganadores de todos los partidos jugados, es decir, aquellos partidos donde el número de goles del equipo local es distinto del número de goles del equipo visitante. Para recuperar el equipo ganador se utiliza la claúsula IF para comparar los goles de ambos equipos. Tras esto, se realiza un INNER JOIN de ambas consultas agrupando los datos por el id del partido y por las iniciales del equipo de los jugadores. De esta forma se evita que se asocien partidos donde los jugadores no han participado. Por último, se realiza una agrupación de los datos a través del nombre del jugador, se ordenan de mayor a menor según el número de veces que aparecen y se limitan los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/practica\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20211118010017_568bc588-1680-433b-badd-5e14b06342f1): SELECT player, count(*) as times FROM (SELECT distinct player, players_a.match_id, team_initials FROM (SELECT match_id, player, team_initials FROM players WHERE line_up = 'S' OR instr(event, 'I') = 1) as players_a INNER JOIN (SELECT match_id, IF(home_goals > away_goals, home_team_initials, away_team_initials) as winner FROM matches WHERE home_goals != away_goals) as match_winners ON players_a.match_id = match_winners.match_id AND players_a.team_initials = match_winners.winner) as player_dist GROUP BY player ORDER BY times DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:player, type:string, comment:null), FieldSchema(name:times, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20211118010017_568bc588-1680-433b-badd-5e14b06342f1); Time taken: 0.228 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20211118010017_568bc588-1680-433b-badd-5e14b06342f1): SELECT player, count(*) as times FROM (SELECT distinct player, players_a.match_id, team_initials FROM (SELECT match_id, player, team_initials FROM players WHERE line_up = 'S' OR instr(event, 'I') = 1) as players_a INNER JOIN (SELECT match_id, IF(home_goals > away_goals, home_team_initials, away_team_initials) as winner FROM matches WHERE home_goals != away_goals) as match_winners ON players_a.match_id = match_winners.match_id AND players_a.team_initials = match_winners.winner) as player_dist GROUP BY player ORDER BY times DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20211118010017_568bc588-1680-433b-badd-5e14b06342f1\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Starting task [Stage-6:MAPREDLOCAL] in serial mode\n",
      "INFO  : Execution completed successfully\n",
      "INFO  : MapredLocal task succeeded\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0019\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0019/\n",
      "INFO  : Starting Job = job_1637192506404_0019, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0019/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0019\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 01:00:27,268 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 01:00:34,464 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.5 sec\n",
      "INFO  : 2021-11-18 01:00:40,615 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.61 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 7 seconds 610 msec\n",
      "INFO  : Ended Job = job_1637192506404_0019\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-3:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1637192506404_0020\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1637192506404_0020/\n",
      "INFO  : Starting Job = job_1637192506404_0020, Tracking URL = http://yarnmaster:8088/proxy/application_1637192506404_0020/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1637192506404_0020\n",
      "INFO  : Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2021-11-18 01:00:47,426 Stage-3 map = 0%,  reduce = 0%\n",
      "INFO  : 2021-11-18 01:00:52,613 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec\n",
      "INFO  : 2021-11-18 01:00:59,810 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.05 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 50 msec\n",
      "INFO  : Ended Job = job_1637192506404_0020\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.61 sec   HDFS Read: 2174271 HDFS Write: 104897 SUCCESS\n",
      "INFO  : Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 4.05 sec   HDFS Read: 112503 HDFS Write: 223 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 11 seconds 660 msec\n",
      "INFO  : Completed executing command(queryId=root_20211118010017_568bc588-1680-433b-badd-5e14b06342f1); Time taken: 43.161 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+--------------------+--------+\n",
      "|       player       | times  |\n",
      "+--------------------+--------+\n",
      "| Wolfgang OVERATH   | 15     |\n",
      "| M�LLER             | 15     |\n",
      "| KLOSE              | 14     |\n",
      "| RONALDO            | 14     |\n",
      "| Franz BECKENBAUER  | 14     |\n",
      "+--------------------+--------+\n",
      "5 rows selected (43.449 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/practica\n"
     ]
    }
   ],
   "source": [
    "sql_statement = \"SELECT player, count(*) as times FROM \\\n",
    "(SELECT distinct player, players_a.match_id, team_initials FROM \\\n",
    "(SELECT match_id, player, team_initials \\\n",
    "FROM players \\\n",
    "WHERE line_up = 'S' OR instr(event, 'I') = 1) as players_a \\\n",
    "INNER JOIN \\\n",
    "(SELECT match_id, IF(home_goals > away_goals, home_team_initials, away_team_initials) as winner \\\n",
    "FROM matches \\\n",
    "WHERE home_goals != away_goals) as match_winners \\\n",
    "ON players_a.match_id = match_winners.match_id AND players_a.team_initials = match_winners.winner) as player_dist \\\n",
    "GROUP BY player \\\n",
    "ORDER BY times DESC \\\n",
    "LIMIT 5;\"\n",
    "\n",
    "!beeline -u \"jdbc:hive2://localhost:10000/practica\" -e \"{sql_statement}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La realización de esta primera práctica me ha resultado muy interesante y me ha ayudado a comprende los conceptos del primer módulo de la asignatura. He podido entender cómo se utiliza el paradigma MapReduce a la hora de tratar con datos y sus principales ventajas: distribución de trabajo, tolerancia a fallos y mejora de la capacidad global de cómputo. Uno de los aspectos que me hubieran gustado probar es la capacidad de cómputo ante la escalabilidad de los datos, ya que el dataset del que se parte no tiene un número grande de datos. Quizá sería interesante futuras prácticas utilizar un dataset con un número de datos mayor para poner a prueba la capacidad de Hadoop. \n",
    "\n",
    "En cuanto a la segunda parte de la práctica, se debe comentar que he decidido realizar la parte de Hive porque tengo conocimientos previos de SQL y he podido comprobar que tienen muchas características en común. También comentar que he valorado positivamente que nos diera a elegir el dataset en esta parte de la práctica. Creo que es una buena forma de motivarnos y de que pensemos en aplicar estos nuevos conocimientos en las áreas que más nos interesan.\n",
    "\n",
    "Como aspecto a mejorar, he echado en falta algún apartado donde se trabajaran conceptos de inyección de datos, ya que por mi experiencia laboral conozco que es una práctica que se realiza habitualmente. \n",
    "Por último, comentar que me han sido de mucha utilidad los ejemplos subidos en el aula virtual así como los ejemplos que se encuentran en el repositorio de GitHub del profesorado.\n",
    "\n",
    "En definitiva, considero que la práctica ayuda a afianzar los conocimientos del primer módulo, que su realización ha sido más interesante al poder darnos la posibilidad de elejir un conjunto de datos para que trabajemos con él, pero me hubiera gustado poner en práctica más conceptos de la parte de inyección de datos.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
