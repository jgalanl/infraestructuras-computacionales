{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e367b597",
   "metadata": {},
   "source": [
    "## Infraestructuras Computacionales para el Procesamiento de Datos Masivos\n",
    "### Práctica del Módulo 3: Gestión de datos en tiempo real (Streaming)\n",
    "### Autor: Jesús Galán Llano\n",
    "#### Correo: jgalan279@alumno.uned.es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aecf6e",
   "metadata": {},
   "source": [
    "Desarrollar un notebook de Jupyter, denominado “tweetCount.ipynb” en el que se utilice como fuente de datos Kafka, y en concreto el topic kafkaTwitter, se establezca una duración de batch de un segundo, y se muestre, cada 5 segundos, el número de tweets recibidos en los últimos 10 segundos. ¿Alrededor de qué número (aproximado) se estabiliza el número de tweets que se procesan en el lapso de tiempo indicado (5 segundos)? ¿Tiene sentido? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091afe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf9e4b",
   "metadata": {},
   "source": [
    "En primer lugar, creamos la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf61b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/16 21:38:04 WARN Utils: Your hostname, jesus-Aspire-A514-52 resolves to a loopback address: 127.0.1.1; using 192.168.1.54 instead (on interface wlp2s0)\n",
      "22/01/16 21:38:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/16 21:38:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"tp3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f756026",
   "metadata": {},
   "source": [
    "Tras esto, especificamos el tipo de entrada de datos que en este caso se corresponde con Apache Kafka. \n",
    "Es importante configurar correctamente el número de brokers de Kafka así como su dirección. La configuración descrita en la memoria\n",
    "consiste de dos servidores, que están disponibles en los puertos 9092 y 9093 en el equipo local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f09ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092,localhost:9093\") \\\n",
    "  .option(\"subscribe\", \"kafkaTwitter\") \\\n",
    "  .option(\"includeHeaders\", \"true\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aefca6",
   "metadata": {},
   "source": [
    "Seguidamente, configuramos la duración del batch y la los parámetros de la ventana. La duración del batch se corresponde con 1 segundo, mientras que\n",
    "cada ventana tiene una duración de 10 segundos y un desplazamiento de 5 segundos. La configuración de la venta se realiza a través de\n",
    "la función window().\n",
    "\n",
    "Para obtener el número de tweets en cada intervalo se agrupan según su marca de tiempo. Utilizando la función count() obtenemos el número de tweets\n",
    "en cada intervalo para luego ordenarlos de forma ascendente según su ventana, es decir, en orden cronológico hacia delante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3829f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedCounts = df.withWatermark(\"timestamp\", \"1 seconds\")\\\n",
    ".groupBy(\n",
    "    window(df.timestamp, \"10 seconds\", \"5 seconds\")\n",
    ").count()\\\n",
    "    .orderBy('window')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ce856",
   "metadata": {},
   "source": [
    "POr último, ejecutamos el proceso para que comience a procesar los tweets según van llegando al topic correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7ca351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/16 19:59:05 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-508d6779-4ad8-4781-a12d-e81b47273935. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "22/01/16 19:59:05 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------+-----+\n",
      "|window|count|\n",
      "+------+-----+\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|2    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|2    |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|87   |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|81   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|161  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|63   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|135  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|27   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|196  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|88   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|151  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|59   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|116  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|14   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 8\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|170  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|68   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 9\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|134  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|37   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 10\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|186  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|89   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 11\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|189  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|153  |\n",
      "|{2022-01-16 19:59:55, 2022-01-16 20:00:05}|61   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 12\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|189  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|194  |\n",
      "|{2022-01-16 19:59:55, 2022-01-16 20:00:05}|123  |\n",
      "|{2022-01-16 20:00:00, 2022-01-16 20:00:10}|21   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 13\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|189  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|194  |\n",
      "|{2022-01-16 19:59:55, 2022-01-16 20:00:05}|191  |\n",
      "|{2022-01-16 20:00:00, 2022-01-16 20:00:10}|89   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 14\n",
      "-------------------------------------------\n",
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2022-01-16 19:59:15, 2022-01-16 19:59:25}|6    |\n",
      "|{2022-01-16 19:59:20, 2022-01-16 19:59:30}|104  |\n",
      "|{2022-01-16 19:59:25, 2022-01-16 19:59:35}|206  |\n",
      "|{2022-01-16 19:59:30, 2022-01-16 19:59:40}|200  |\n",
      "|{2022-01-16 19:59:35, 2022-01-16 19:59:45}|194  |\n",
      "|{2022-01-16 19:59:40, 2022-01-16 19:59:50}|199  |\n",
      "|{2022-01-16 19:59:45, 2022-01-16 19:59:55}|189  |\n",
      "|{2022-01-16 19:59:50, 2022-01-16 20:00:00}|194  |\n",
      "|{2022-01-16 19:59:55, 2022-01-16 20:00:05}|202  |\n",
      "|{2022-01-16 20:00:00, 2022-01-16 20:00:10}|157  |\n",
      "|{2022-01-16 20:00:05, 2022-01-16 20:00:15}|57   |\n",
      "+------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowedCounts\\\n",
    "        .writeStream\\\n",
    "        .outputMode('complete')\\\n",
    "        .format('console')\\\n",
    "        .option('truncate', 'false')\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a547674",
   "metadata": {},
   "source": [
    "Tras realizar varios procesamientos se decide parar el proceso para contestar a las preguntas que se plantean.\n",
    "\n",
    "Como se puede observar en la salida del programa, el número de tweets procesados por el programa tiende a estabilizarse\n",
    "de forma aproximada en 200 tweets. Esto es lógico teniendo en cuenta lo siguiente: el productor emite los tweets entre 0 y 0,1 segundos, produciendo 10 tweets por\n",
    "segundo en el peor de los caos. Por tanto, el promedio de producción de tweets se corresponde con 20 tweets por segundo. Si se multiplica este número\n",
    "por el tamaño de la ventana, 10 segundos, se obtiene el número de tweets que se deberían de procesar en cada ventana. \n",
    "\n",
    "Se debe comentar que este número no es exacto, como se ha comprobado, porque existen otros factores que influyen en el rendimiento del procesamiento, como la latencia\n",
    "de red o la disponibilidad de recursos computacionales."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8de8a589add48b80f6827af05e807dbcd2bd3827f84dec81fe71df8e7bb571de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
